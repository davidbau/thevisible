<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Welcome | The Visible Net</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="Welcome to The Visible Net, a blogging outlet for the “East-Coast Contingent” of mechanistic interpretability machine intelligence researchers.
Introductions
I am David Bau, an assistant professor at Northeastern University, and my lab focuses on understanding the interpretable mechanisms that emerge from large-scale machine learning. I am a late-career academic. I returned to finish my PhD at MIT several years ago, after two decades building products and leading product development for Google, Microsoft, and startups.">
    <meta name="generator" content="Hugo 0.68.3" />
    
    
    
    
      <meta name="robots" content="noindex, nofollow">
    

    
<link rel="stylesheet" href="/ananke/css/main.min.css" >



    
    
    
      

    

    
    
    <meta property="og:title" content="Welcome" />
<meta property="og:description" content="Welcome to The Visible Net, a blogging outlet for the “East-Coast Contingent” of mechanistic interpretability machine intelligence researchers.
Introductions
I am David Bau, an assistant professor at Northeastern University, and my lab focuses on understanding the interpretable mechanisms that emerge from large-scale machine learning. I am a late-career academic. I returned to finish my PhD at MIT several years ago, after two decades building products and leading product development for Google, Microsoft, and startups." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://thevisible.net/articles/000-welcome/" />
<meta property="article:published_time" content="2023-03-19T15:54:00-04:00" />
<meta property="article:modified_time" content="2023-03-19T15:54:00-04:00" />
<meta itemprop="name" content="Welcome">
<meta itemprop="description" content="Welcome to The Visible Net, a blogging outlet for the “East-Coast Contingent” of mechanistic interpretability machine intelligence researchers.
Introductions
I am David Bau, an assistant professor at Northeastern University, and my lab focuses on understanding the interpretable mechanisms that emerge from large-scale machine learning. I am a late-career academic. I returned to finish my PhD at MIT several years ago, after two decades building products and leading product development for Google, Microsoft, and startups.">
<meta itemprop="datePublished" content="2023-03-19T15:54:00-04:00" />
<meta itemprop="dateModified" content="2023-03-19T15:54:00-04:00" />
<meta itemprop="wordCount" content="384">



<meta itemprop="keywords" content="" /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Welcome"/>
<meta name="twitter:description" content="Welcome to The Visible Net, a blogging outlet for the “East-Coast Contingent” of mechanistic interpretability machine intelligence researchers.
Introductions
I am David Bau, an assistant professor at Northeastern University, and my lab focuses on understanding the interpretable mechanisms that emerge from large-scale machine learning. I am a late-career academic. I returned to finish my PhD at MIT several years ago, after two decades building products and leading product development for Google, Microsoft, and startups."/>

	
  </head>

  <body class="ma0 avenir bg-near-white">

    
   
  

  <header>
    <div class="bg-black">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="/" class="f3 fw2 hover-white no-underline white-90 dib">
      
        The Visible Net
      
    </a>
    <div class="flex-l items-center">
      

      
      
<div class="ananke-socials">
  
</div>

    </div>
  </div>
</nav>

    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref b helvetica tracked">
          
        ARTICLES
      </aside>
      










  <div id="sharing" class="mt3 ananke-socials">
    
  </div>


      <h1 class="f1 athelas mt3 mb1">Welcome</h1>
      
      
      
      <time class="f6 mv4 dib tracked" datetime="2023-03-19T15:54:00-04:00">March 19, 2023</time>
      

      
      
    </header>
    <div class="nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-two-thirds-l"><p>Welcome to The Visible Net, a blogging outlet for the “East-Coast Contingent” of mechanistic interpretability machine intelligence researchers.</p>
<p>Introductions</p>
<p>I am David Bau, an assistant professor at Northeastern University, and my lab focuses on understanding the interpretable mechanisms that emerge from large-scale machine learning.  I am a late-career academic. I returned to finish my PhD at MIT several years ago, after two decades building products and leading product development for Google, Microsoft, and startups.</p>
<p>I plan for this to be a shared blogging space for my students, collaborators, and others working on mechanistic interpretability.</p>
<p>I am often asked, in this era when many professors and machine learning graduate students are getting lured away from academic positions to join industry labs at OpenAI or Google etc: “David, why are you going in the opposite direction?”  A flip answer with a grain of truth is, “I have already done the corporate stuff, and I like swimming against the tide.”  But my real answer is this: Companies are in the business of making <em>things</em>, but universities are in the business of making <em>ideas</em>. So academia is where the <em>real action is</em> as the field of computer science redefines itself in the face of large-scale machine learning.</p>
<p>In this new era of self-programming computers, it is no longer enough to make intelligent systems that work. We need to create a science of understanding how intelligent systems work <em>after we create them</em>.  That means we will need new ideas, new methods, and a search for new abstractions, and we need to be open to the ambition of cracking the ancient puzzle of <em>what thinking is</em>. That kind of idea generation demands the transparent, argumentative, risk-taking, teaching-focused, cooperative-competitive scrutiny of academic research. Companies will be incentivized to keep secrets as they try to establish their competitive advantages, and as a result it will be very hard for companies to generate enough ideas to make progress on the important ideas in the long run.  Finding the right abstractions for the next generation of insights in this new era of computer science is something that I believe is beyond the capacity for any private company to take on: it is the job of the open academic research community.</p>
<p>So: welcome.  I will set the tone here with a couple of initial posts.</p>
<ul class="pa0">
  
</ul>
<div class="mt6 instapaper_ignoref">
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="https://thevisible.net/" >
    &copy;  The Visible Net 2023 
  </a>
    <div>
<div class="ananke-socials">
  
</div>
</div>
  </div>
</footer>

  </body>
</html>
